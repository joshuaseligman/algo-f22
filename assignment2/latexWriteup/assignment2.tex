%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% CMPT 435
% Fall 2022
% Assignment 2
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from: http://www.LaTeXTemplates.com
% Original author: % Frits Wenneker (http://www.howtotex.com)
% License: CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% Modified by Alan G. Labouseur  - alan@labouseur.com
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[letterpaper, 10pt,DIV=13]{scrartcl} 

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm,xfrac} % Math packages
\usepackage{sectsty} % Allows customizing section commands
\usepackage{graphicx}
\usepackage{algorithm, algpseudocode}
\usepackage{listings}
\usepackage{parskip}
\usepackage{lastpage}
\usepackage{color}
\usepackage{qtree}

\allsectionsfont{\normalfont\scshape} % Make all section titles in default font and small caps.

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers

\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{page \thepage\ of \pageref{LastPage}} % Page numbering for right footer

\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs.

\binoppenalty=3000
\relpenalty=3000

\algrenewcommand{\algorithmiccomment}[1]{\hskip1em\textit{$//$ #1}}

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
   \normalfont \normalsize 
   \textsc{CMPT 435 - Fall 2022 - Dr. Labouseur} \\[10pt] % Header stuff.
   \horrule{0.5pt} \\[0.25cm] 	% Top horizontal rule
   \huge Assignment Two  \\     	    % Assignment title
   \horrule{0.5pt} \\[0.25cm] 	% Bottom horizontal rule
}

\author{Josh Seligman \\ \normalsize joshua.seligman1@marist.edu}

\date{\normalsize\today} 	% Today's date.

\begin{document}
\maketitle % Print the title

\section{Selection Sort}\label{selectionSortSection}
\subsection{The Algorithm}
Selection sort is a sorting algorithm that, for each iteration of the array, selects the smallest (or largest) element of the unsorted part of the array and places the element into its sorted position. As shown in the pseudocode for the sort in Algorithm \ref{algorithm:selectionSort}, selection sort works with the subset of the array in the range $[i,~n)$ in each iteration because the elements in the indices less than $i$ are already sorted and do not have to be checked. Thus, as more elements get sorted, the quicker each iteration becomes because a smaller portion of the array is compared until $i = n - 2$, which is the final iteration of the algorithm. Selection sort is also very consistent in that it runs in the same amount of time regardless of the order of the elements and has both a best and worst case of $n^2$, which will be analyzed in further detail in Section \ref{selectionAnalysis}.

\begin{algorithm}
  \caption{Selection Sort Algorithm}
  \label{algorithm:selectionSort}
  %Documentation for algorithmicx: https://texdoc.org/serve/algorithmicx/0
  \begin{algorithmic}[1]
      \Procedure{SelectionSort}{$arr$}
        \For{$i \gets 0,~n - 2$} \Comment{Iterate through the second to last element as an array of size 1 is sorted}
          \State $smallestIndex \gets i$
          \For{$j \gets i + 1,~n - 1$} \Comment{Iterate through the remainder of the array}
            \If{$arr[j] < arr[smallestIndex]$}
              \State $smallestIndex \gets j$ \Comment{Set the new smallest index if a smaller element is found}
            \EndIf
          \EndFor
          \State $swap(arr,~i,~smallestIndex)$ \Comment{Place the smallest item in the subarray into its sorted place}
        \EndFor
      \EndProcedure
  \end{algorithmic}
\end{algorithm}

\subsection{Asymptotic Analysis and Comparisons}\label{selectionAnalysis}
Listing \ref{lst:selectionSortListing} contains the C++ code implementing selection sort on lines 6 - 25. Line 6 defines a loop that iterates $n - 1$ times and contains 2 assignments and a comparison, all of which operate in constant time for each iteration. Thus, line 6 will take $(n - 1) * C_{1}$ time, where $C_{1}$ is the time needed for each of the operations. Next, line 8 is an assignment, which take a constant time and executes $n - 1$ times because it is in the outer loop, resulting in a time of $(n - 1) * C_{2}$, where $C_{2}$ is the constant time needed for the assignment. Line 11, similar to line 6, defines a loop with 3 constant time expressions, which can be marked as $C_{3}$. However, since it is nested inside of the loop on line 6, the total number of iterations of the inner loop is more complex. In the first iteration of the outer loop, the inner loop runs $n - 1$ times. From there, each corresponding iteration of the outer loop results in one less iteration of the inner loop with a minimum of 1 pass on the inner loop when $i = n - 2$. Therefore, the total number of times the inner loop on line 11 will be called is $\sum_{k = 1} ^{n - 1} k$, which by the formula for the sum of the first $N$ natural numbers, is equal to $\frac{(n - 1)(n - 1 + 1)}{2} = \frac{1}{2}n^2 - \frac{1}{2}n$. Thus, the total time to execute line 11 is $(\frac{1}{2}n^2 - \frac{1}{2}n) * C_{3}$. Next, line 13 contains a comparison that, since it is nested inside the inner loop, will run in $(\frac{1}{2}n^2 - \frac{1}{2}n) * C_{4}$ time, where $C_{4}$ is the time needed to make the comparison. Line 15 is a simple assignment and, just like line 14, will run in $(\frac{1}{2}n^2 - \frac{1}{2}n) * C_{5}$, where $C_{5}$ is the time to perform the assignment. The assignment on line 18 is purely for collecting data and not part of the algorithm and, therefore, will be excluded from the asymptotic analysis of selection sort. Line 19 is the end of the inner loop, and represents an unconditional branch back to the top of the loop, which means it runs the same number of iterations as the loop, which is $(\frac{1}{2}n^2 - \frac{1}{2}n) * C_{6}$, where $C_{6}$ is the time needed to execute the branch. Next, lines 22-24 are all assigments, which run in constant time, and are located in the outer loop. Thus, they run in $(n - 1) * C_{7}$ time, where $C_{7}$ is the time needed to perform the swap. Lastly, line 25 is the close and unconditional branch for the outer loop, which will run in $(n - 1) * C_{8}$ time, where $C_{8}$ is the time to execute the unconditional branch. Overall, when adding up the runtimes of each line and dropping the constants, the sum is $4 * (n - 1) + 4 * (\frac{1}{2}n^2 - \frac{1}{2}n) = 2n^2 + 2n - 4 \approx n^2 + n$ is $O(n^2)$.

As shown in Table \ref{comparisonsTable}, selection sort is very consistent with the number of comparisons made as, regardless of the state of the list, it always makes $\frac{1}{2}n^2 - \frac{1}{2}n$ comparisons. This is no coincidence as it is also the number of times the algorithm's inner loop iterates, which means that the selection sort will run very consistently for all lists, no matter the state of the array prior to running the algorithm.

\section{Insertion Sort}\label{insertionSortSection}
\subsection{The Algorithm}\label{insertionSortAlgo}
Insertion sort in a sorting algorithm that places an element in its sorted place by sliding previously sorted elements over until the sorted position is found for the element. As shown in Algorithm \ref{algorithm:insertionSort}, the element that is being sorted is only compared to elements in positions $[0, i - 1]$ because these are the elements that have been worked with so far and are known to be in order. Therefore, the elements in this area, as described before, are shifted over until one is less than the value being sorted or until $j < 0$, which will break out of the while loop. Unlike selection sort, the performance of insertion sort varies based on the state of the input array, which will be explored more in detail in Section \ref{insertionAnalysis}.

\begin{algorithm}
  \caption{Insertion Sort Algorithm}
  \label{algorithm:insertionSort}
  %Documentation for algorithmicx: https://texdoc.org/serve/algorithmicx/0
  \begin{algorithmic}[1]
      \Procedure{InsertionSort}{$arr$}
        \For{$i \gets 1,~n - 1$} \Comment{Start at index 1 because the first element is already sorted}
          \State $currentVal \gets arr[i]$
          \State $j \gets i - 1$
          \While{$j \geq 0 ~\textbf{and} ~currentVal < arr[j]$} \Comment{Find the position to place the element}
            \State $arr[j + 1] \gets arr[j]$ \Comment{Shift the element over because it is greater than the current value}
            \State $j \gets j - 1$
          \EndWhile
          \State $arr[j + 1] \gets currentVal$ \Comment{Place the element in its sorted position}
        \EndFor
      \EndProcedure
  \end{algorithmic}
\end{algorithm}

\subsection{Asymptotic Analysis and Comparisons}\label{insertionAnalysis}
For instance, if the array is already completely sorted, the while loop on line 5 in Algorithm \ref{algorithm:insertionSort} will never be entered because each element is already sorted and in its proper position. This makes the best case runtime of insertion sort $\Omega(n)$ because the inner loop is never run and the outer loop just iteraties through the array once. However, the worst case of insertion sort is when the array is in reverse order. This becomes the worst case because, as shown within the while loop in Algorithm \ref{algorithm:insertionSort}, each element will have to be compared with every other element, which will cause $j$ to end at $-1$ and the element gets inserted at the front of the array. This results in a worst case runtime complexity of $O(n^2)$, which will be analyzed and proved in detail in Section \ref{insertionAnalysis}.


The code implementation of insertion sort is in Listing \ref{lst:insertionSortListing} on lines 7-34. As mentioned in Section \ref{insertionSortAlgo}, the worst case for insertion sort is when the array is in reverse order because every element will have to be compared to every element within the sorted portion of the array. First, the outer loop begins on line 7 and contains 2 assignments and a comparison. Based on the definition of the loop, these statements will run $n - 1$ times, which means the line will run in $(n - 1) * C_{1}$ time, where $C_{1}$ is the time needed to execute these statements. Next, line 9 is a basic assignment and, since it is in the loop, will run in $(n - 1) * C_{2}$ time, where $C_{2}$ is the time to perform the assignment. Line 12 is also an assignment in the outer loop, which will run in $(n - 1) * C_{3}$ time, where $C_{3}$ is the time to execute the assignment. Next, line 16 contains the definition for a while loop, which has 2 comparisions. Since the worst case requires each element to be compared to all of the other sorted elements, the while loop will terminate when $j = -1$. Thus, when $i = 1$, the while loop will only iterate once, and the number of iterations for the while loop will increment with a max of $n - 1$ for when $i = n - 1$. The total iterations is explained in Section \ref{selectionAnalysis} as being $\sum_{k = 1} ^{n - 1} k = \frac{(n - 1)(n - 1 + 1)}{2} = \frac{1}{2}n^2 - \frac{1}{2}n$, which means the loop on line 16 will run in $(\frac{1}{2}n^2 - \frac{1}{2}n) * C_{4}$ time, where $C_{4}$ is the time to perform the comparisons. Line 18 is just for counting the comparisons and will be excluded from the analysis of the algorithm. Next, the assignment on line 21 runs in constant time and, since it is in the inner loop, will run in $(\frac{1}{2}n^2 - \frac{1}{2}n) * C_{5}$ time, where $C_{5}$ is the time to perform the assignment. Line 22 also contains an assignment and runs in $(\frac{1}{2}n^2 - \frac{1}{2}n) * C_{6}$ time, where $C_{6}$ is the time to perform the assignment. Line 23 is the end of the while loop, which translates to an unconditional branch to the top of the loop, which will run in $(\frac{1}{2}n^2 - \frac{1}{2}n) * C_{7}$ time, where $C_{7}$ is the time to execute the branch. Lines 28-30 are used for counting the comparisons and are excluded from the analysis of insertion sort. Next, line 33 is an assignment to put the element in its sorted place, which will run in $(n - 1) * C_{8}$ time because it is in the outer loop, where $C_{8}$ is the time to perform the assignment. Lastly, line 34 is the end of the for loop, which is an unconditional branch to the top of the loop, which will run in $(n - 1) * C_{9}$, where $C_{9}$ is the time to perform the branch. Overall, when summing up each runtime and dropping the constants, the total is $5 * (n - 1) + 4 * (\frac{1}{2}n^2 - \frac{1}{2}n) = 2n^2 + 3n - 5 \approx n^2 + n$ is $O(n^2)$.

In Table \ref{comparisonsTable}, insertion sort is shown to have 3 very different outcomes for the lists that were used for testing relative to selection sort. First, insertion sort used about half the number of comparisons as selection sort for a list of 666 shuffled magic items. This is because the inner loop of insertion sort may terminate when $arr[j] < currentVal$ (see line 16 in Listing \ref{lst:insertionSortListing}) and in a randomly shuffled list, the probability of $arr[j] < currentVal$ will be around 50\%. Therefore, insertion sort will on average be about 50\% more efficient than selection sort, but is still classified as $O(n^2)$ beause it is still running at a function of $n^2$. Next, when the list is already shuffled, insertion sort only makes $n-1$ comparisons. As mentioned in Section \ref{insertionSortAlgo}, the best case for insertion sort is $\Omega(n)$ because the inner loop will never be entered as the second condition for $arr[j] < currentVal$ will always return false. This means there will be only 1 comparison made for each iteration of the outer loop, which equates to $n - 1$ comparisions. Lastly, Section \ref{insertionSortAlgo} mentioned that the worst case for insertion sort is when the list is in reverse order because every element will have to compare itself with all of the elements in the sorted portion of the array. This causes insertion sort to have the same number of comparisons as selection sort for a reversed list at $\frac{1}{2}n^2 - \frac{1}{2}n$, which is also the same number of iterations as the inner loop for insertion sort and makes insertion sort $O(n^2)$.

\section{Merge Sort}
\subsection{The Algorithm}
Merge sort is a divide and conquer sorting algorithm that continues to divide an array up until it has $n$ subarrays of size 1, which, by definition, are all sorted. From there, the subarrays are merged together by comparing the elements in each subarray to determine the sorted order of the combined subarrays. Eventually, the full array will be merged back together will all of the elements fully sorted. As displayed in Algorithm \ref{algorithm:mergeSort} in the $MergeSort$ procedure, since the sort is a divide and conquer algorithm, merge sort takes advantage of recursion to make the problem smaller until it reaches its base case of $length(arr) <= 1$, which is shown on line 2. Additionally, on lines 4 and 5, merge sort always divides a given array in half, which makes its performance very predictable and consistent, which will be discussed more in detail in Section \ref{mergeSortAnalysis}.

\begin{algorithm}
  \caption{Merge Sort Algorithm}
  \label{algorithm:mergeSort}
  %Documentation for algorithmicx: https://texdoc.org/serve/algorithmicx/0
  \begin{algorithmic}[1]
      \Procedure{MergeSort}{$arr$}
        \If{$length(arr) > 1$} \Comment{An array of size 1 is already sorted}
          \State $mid = floor((length(arr)) / 2)$ \Comment{Get the middle index of the array for splitting it in half}
          \State $MergeSort(arr[0:mid])$ \Comment{Perform merge sort on the first half of the array (index 0 - mid, inclusive)}
          \State $MergeSort(arr[mid + 1:length(arr) - 1])$ \Comment{Perform merge sort on the second half of the array}
          \State $Merge(arr, mid)$ \Comment{Merge the 2 subarrays together in order}
        \EndIf
      \EndProcedure
      \\
      \Procedure{Merge}{$arr$, $mid$}
        \State $leftIndex \gets 0$ \Comment{Index for the left subarray}
        \State $rightIndex \gets mid + 1$ \Comment{Index for the right subarray}
        \State $newArr \gets [~]$
        \For{$i \gets 0,~length(arr) - 1$} \Comment{Iterate through all elements}
          \If{$rightIndex >= length(arr)$} \Comment{All the right subarray items are already in $newArr$}
            \State $newArr[i] = arr[leftIndex]$ \Comment{Add the next item from the left subarray}
            \State $leftIndex++$
          \ElsIf{$leftIndex > mid$} \Comment{All the right subarray items are already in $newArr$}
            \State $newArr[i] = arr[rightIndex]$ \Comment{Add the next item from the right subarray}
            \State $rightIndex++$
          \ElsIf{$arr[leftIndex] < arr[rightIndex]$} \Comment{The next element from the left subarray is less than the next element from the right subarray}
            \State $newArr[i] = arr[leftIndex]$ \Comment{Add the next item from the left subarray}
            \State $leftIndex++$
          \Else
            \State $newArr[i] = arr[rightIndex]$ \Comment{Add the next item from the right subarray}
            \State $rightIndex++$
          \EndIf
        \EndFor
        \For{$j \gets 0,~length(arr) - 1$}
          \State $arr[j] \gets newArr[j]$ \Comment{Transfer the sorted elements to the original array}
        \EndFor
      \EndProcedure
  \end{algorithmic}
\end{algorithm}

\subsection{Asymptotic Analysis and Comparisons}\label{mergeSortAnalysis}
The C++ implementation of merge sort can be found in Listing \ref{lst:mergeSortListing}, more specifically lines 6-28. As shown on line 14, the array is always split in half for each successive call of merge sort until the subarray is of length 1. The recursion tree for merge sort is displayed below.

% Documentation: https://www.ling.upenn.edu/advice/latex/qtree/qtreenotes.pdf
\Tree [.$T(n)$
        [.$T(\frac{n}{2})$
          [.$T(\frac{n}{4})$
            [.{...} 
              [.$T(\frac{n}{2^k})$ $O(1)$ ]
            ]
            [.{...} 
              [.$T(\frac{n}{2^k})$ $O(1)$ ]
            ]
          ]
          [.$T(\frac{n}{4})$ 
            [.{...} 
              [.$T(\frac{n}{2^k})$ $O(1)$ ]
            ]
            [.{...} 
              [.$T(\frac{n}{2^k})$ $O(1)$ ]
            ]
          ]
        ]
        [.$T(\frac{n}{2})$
          [.$T(\frac{n}{4})$
            [.{...} 
              [.$T(\frac{n}{2^k})$ $O(1)$ ]
            ]
            [.{...} 
              [.$T(\frac{n}{2^k})$ $O(1)$ ]
            ]
          ]
          [.$T(\frac{n}{4})$ 
            [.{...} 
              [.$T(\frac{n}{2^k})$ $O(1)$ ]
            ]
            [.{...} 
              [.$T(\frac{n}{2^k})$ $O(1)$ ]
            ]
          ]
        ]
      ]

As shown in the recursion tree, the array is broken up into smaller subarrays until the subarray is small enough that it is solved using a constant time operation. Additionally, the last call is on an array of size $\frac{n}{2^k}$. Since the array is being divided in half each time, $k$ is the number of levels in the tree, which is $log_2n$.

Next, after the 2 subarrays are sorted, they are merged together for the conquer phase, which is on lines 30-80 of Listing \ref{lst:mergeSortListing}. The beginning of the function (lines 32-40) are all assignments, which run in constant time. Next, there is a for loop that iterates through the length of the subarray being merged. The body is a large if-else block with comparisons and assignments, which is all $O(1)$ and makes the loop it is contained in run in $O(n)$ time. Lastly, lines 74-76 define a loop that iterates through each element in the subarray, which is also $O(n)$. Therefore, the runtime for the merge function is about $2n + 1$, which is $O(n)$.

At each level of the tree, the merge function will work with exactly $n$ elements. For instance, in the first level of the tree, the left subarray will be merged from 2 subarrays of size $\frac{n}{4}$, which means that the merge function will work with $\frac{n}{2}$ elements. However, since there are 2 subarrays of size $\frac{n}{2}$, the merge function will be called again to handle the other subarray and, therefore, the level will end up merging $n$ elements. Thus, one can multiply $n$ by the number of levels to get the runtime complexity, which is $O(n * log_2n)$.

As shown in Table \ref{comparisonsTable}, merge sort is significantly more efficient at sorting the magic items by using around 5,500 comparisons, which is a little less than the algorithm's runtime of $O(n * log_2n)$. The reason for the number of comparisons being less than 6246.67 ($666 * log_{2}666$) is explained on lines 48 and 52 in Listing \ref{lst:mergeSortListing} as the merging of an entire subarray before the other will result in the algorithm merging the remainder of the other subarray without needing to compare the elements. Regardless, the number of comparisons is still not far from $O(n * log_2n)$. Additionaly, merge sort is very similar to selection sort in that it will perform consistently for any permutation of an array of size $n$. This is shown in the smaller test cases, which perform almost identically despite being in differing orders. Also, one interesting point to note is the performance of insertion sort versus merge sort for the already sorted list. Since insertion sort has a best case of $\Omega(n)$, it is more efficient than merge sort when the array is already mostly sorted. This leads to the idea of hybrid algorithms that may use one sort up until a certain point and switch to a second algorithm that is more efficient in the end game of the sorting process.

\section{Appendix}
\subsection{Comparisons Table}\label{comparisonsTable}
\begin{center}
  \begin{tabular}{|c|c|c|c|}
    \hline
    Algorithm & List & Comparisons & Time \\
    \hline
    Selection Sort & 666 magic items, shuffled & 221445 & 3625271 ns \\
    \hline
    & 20 Yankees greats, sorted & 190 & 3673 ns \\
    \hline
    & 20 Yankees greats, reversed & 190 & 3636 ns \\
    \hline
    Insertion Sort & 666 magic items, shuffled & 104628 & 2523161 ns \\
    \hline
    & 20 Yankees greats, sorted & 19 & 795 ns \\
    \hline
    & 20 Yankees greats, reversed & 190 & 2966 ns \\
    \hline
    Merge Sort & 666 magic items, shuffled & 5417 & 1006113 ns \\
    \hline
    & 20 Yankees greats, sorted & 48 & 6751 ns \\
    \hline
    & 20 Yankees greats, reversed & 40 & 6745 ns \\
    \hline
  \end{tabular}
\captionof{table}{A table of the number of comparisons made and time to complete each sort on a variety of lists.}
\end{center}

\lstset{numbers=left, numberstyle=\tiny, stepnumber=1, numbersep=5pt}

% Colors and lstset for syntax highlighting from https://www.overleaf.com/latex/examples/syntax-highlighting-in-latex-with-the-listings-package/jxnppmxxvsvk
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\lstset{
  backgroundcolor=\color{white},   % choose the background color
  basicstyle=\footnotesize,        % size of fonts used for the code
  breaklines=true,                 % automatic line breaking only at whitespace
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  keywordstyle=\color{blue},       % keyword style
  stringstyle=\color{mymauve},     % string literal style
}

\subsection{Selection Sort}\label{selectionSortListing}
\lstinputlisting[caption = Selection Sort (C++), label = lst:selectionSortListing, language = C++, firstline = 8, lastline = 36, firstnumber = 1]{./../sortsAndShuffles.cpp}

\subsection{Insertion Sort}\label{insertionSortListing}
\lstinputlisting[caption = Insertion Sort (C++), label = lst:insertionSortListing, language = C++, firstline = 38, lastline = 75, firstnumber = 1]{./../sortsAndShuffles.cpp}

\subsection{Merge Sort}\label{mergeSortListing}
\lstinputlisting[caption = Merge Sort (C++), label = lst:mergeSortListing, language = C++, firstline = 77, lastline = 156, firstnumber = 1]{./../sortsAndShuffles.cpp}

\end{document}